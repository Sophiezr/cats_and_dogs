# cats_and_dogs
This repository consists of a pipeline for image classification and segmentation using cats and dogs dataset.
## Design considerations
In this dataset, each image features one or two pets. This means there are two design choices in order to output segmentation and classification information:

- Use the position information of each pet in images (i.e. bounding box) and train an instant segmentation model like Mask R-CNN
- Develop an image preprocessing algorithm that separates images containing two pets into two distinct images, ensuring that each pet is isolated. Subsequently, construct a multi-headed algorithm capable of performing both segmentation and classification tasks. This algorithm will enable the accurate segmentation of individual pets within the images, as well as their breed into appropriate categories.

Given the absence of bounding box information in the dataset and the potential challenges associated with extracting accurate position information, the second design option seems more suitable for this task. This approach bypasses the need for explicit localization by directly segmenting and classifying the pets within the images. 
## Solution
- Employ a method to detect and split two-pet images prior to feeding them into the multi-headed model for breed classification and mask generation. In this case, the fasterrcnn_resnet50_fpn model from the Torchvision library is utilized to detect the number of pets in an image.
-  I have developed a multi-headed model that combines segmentation and classification tasks. The model utilizes a customized version of the UNet architecture, which has been tailored to simultaneously output both pet masks and breed categories.
## Configuration
The solution is trained and tested on a Linux machine runnig Ubuntu 22.04.1 LTS.
Create conda environment and activate it using the following commands:
```
conda env create -f dir/to/environment.yaml
conda activate cats_and_dogs_v3
```

## Project Structure
```
|--- cats_and_dogs
|    |--- output
|    |    |--- pred_masks 
|    |--- |--- |--- some of output masks
|    |    |--- metrics
|    |--- |--- |--- breed_detection_confusion_matrix.png
|    |--- |--- |--- metrics.txt
|    |    |--- plot
|    |--- |--- |--- breed_detection_confusion_matrix.png
|    |--- |--- |--- metrics.txt
|    |    |--- model (copy weight here)
|    |    |--- test_rcnn 
|    |--- inputs
|    |--- |--- csv
|    |--- |--- |--- df_refined_test.csv
|    |--- |--- |--- df_refined_train.csv
|    |--- |--- |--- df_refined_val.csv
|    |--- |--- |--- df_test.csv
|    |--- |--- |--- df_val.csv
|    |--- |--- |--- df_train.csv
|    |--- |--- |--- df_test_for_test.csv
|    |--- |--- |--- df_train_for_test.csv
|    |--- |--- |--- df_val_for_test.csv
|    |--- data.py
|    |--- data_analysis_and_design_considerations.ipynb
|    |--- Performance_analysis.ipynb
|    |--- model.py
|    |--- test.py
|    |--- train.py
|    |--- inference.py
|    |--- environment.yml
|    |--- README.md
```
- output/pred_masks directory contains some of the output masks. Only limited number of output masks saved to file.
- output/metric directory contains classification and segmentation performance metrics in metrics.txt, classification confusion matrix.
- output/plot directory contains loss plot for classification and segmentation, and accuracy plot for classification during training.
- output/models directory should be created and weight needs to be coppied in this directory.
- output/test_rcnn directory should be created in case of testing object detection model.
- input/csv/ directory contains the followings:
  - The original dataset underwent minor processing and was subsequently split into training, validation, and test sets. The test dataset, consisting of both two-pet and single-pet images, is utilized during the inference phase to evaluate the end-to-end solution.
      - df_train.csv
      - df_val.csv
      - df_test.csv
  - Refined datasets. These datasets are generated by splitting two-pet images and saving them as individual files. They exclusively consist of single-pet images, both after the image split and in their original form. These datasets are intended for use as inputs to the multi-headed classification and segmentation model.
      - df_refined_train.csv
      - df_refined_val.csv
      - df_refined_test.csv
  - These datasets are specifically designed for testing the training and testing processes of the model. They exclusively consist of single-pet images extracted from the original dataset. The purpose of creating these datasets is to ensure that the tests do not fail if the images are not split before testing the model. By including all the necessary images in the dataset, the tests can be conducted successfully without encountering missing image errors.  
      - df_train_for_test.csv
      - df_val_for_test.csv
      - df_test_for_test.csv
- test.py is a python module to test the model with the df_refined_test.csv and generate the results presented in *output/metrics* directory.
- train.py is a python module to train the multi-headed segmentation and classification model. 
- data_analysis_and_design_consideration.ipynb is a notebook that contains explanation about the steps I took to propose the solution and build the model.
- inference.py is a python module used during inference. It is the end-to-end solution. It takes images; and outputs masks, cat dog or both, and breed.
- environment.yml is used to create conda environment.
- README.md contains summary of solution, configuration, and usage of the model.
## Usage
Download the weight from [here](https://drive.google.com/file/d/1b3-JBIUEvJspwdXZM3Z7RZPl42DtCMTw/view?usp=sharing) and copy to *output/model/* directory.
### I recommend start with running inference.py to see how end-to-end solution works.
python dir/to/inference.py -img_dir 'path/to/images'
### Train the segmentation and classification model
python dir/to/train.py -img_dir 'path/to/images' -cpu_workers num_of_cpu -batch_size batch_size
### Test the segmentation and classification model
python dir/to/test.py -img_dir 'path/to/images' -cpu_workers num_of_cpu -batch_size batch_size
## Scale the solution to detect any number of cats and dogs
To accomplish this, a modification can be made to the initial part of the solution by training a specific model to detect cats and dogs in the images instead of using a generic object detection model. By doing so, the identified pets can be cropped and fed into the multi-headed segmentation and classification model. The generic model used in this solution detects any object in the image and lacks the necessary specificity for effective scaling.This approach also allows for a more targeted and accurate detection of the desired classes, ultimately improving the performance and quality of the subsequent tasks.
## Future improvement
- Training a specific model to detect cats and dogs in the images instead of using a generic object detection model.
- Given the availability of location information, it would be worthwhile to explore the training of an instance segmentation model instead of training separate models for classification and segmentation tasks.
- Start with training two separate models for breed detection and pet segmentation. This allows for a baseline assessment of the individual models' performance before considering their integration. By training separate models, we can evaluate their effectiveness in detecting and classifying pets and breeds accurately. This step provides a means to establish a performance benchmark and verify that each model performs satisfactorily on its respective task. We can then explore joining them to create a unified model that performs both pet segmentation and breed detection. 
- Hyperparameters tuning
- To explore alternatives to the UNet architecture for the segmentation task, it is worth considering other popular architectures.
